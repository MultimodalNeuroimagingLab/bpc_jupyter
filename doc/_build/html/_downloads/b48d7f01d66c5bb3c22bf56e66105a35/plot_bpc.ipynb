{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Basis Profile Curve (BPC) analysis\n\nIn this example, we will show how to use basis profile curve (BPC)\nanalysis to quantify the shapes and strengths of connectivity from\nelectrical stimulation sites to a recording site.\n\nTo do: format citation  https://doi.org/10.1101/2021.01.24.428020\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Alex Rockhill <aprockhill@mailbox.org>\n#          Dora Hermes\n#\n# License: BSD-3-Clause\n\nfrom pathlib import Path\nimport numpy as np\n\nimport openneuro\nimport mne\nimport mne_bids\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom sklearn.decomposition import NMF\nfrom scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, download the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = 'ds003708'\nroot = Path('..') / '..' / dataset\n# openneuro.download(dataset=dataset, target_dir=root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data and plot channel positions and events.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = mne_bids.BIDSPath(\n    subject='01', session='ieeg01', task='ccep', run='01', root=root)\nraw = mne_bids.read_raw_bids(path)\n\ntrans = mne.transforms.Transform(fro='head', to='mri', trans=np.eye(4))  # identity\nfig = mne.viz.plot_alignment(\n    raw.info, trans=trans, subject='fsaverage', surfaces='pial')\nmne.viz.set_3d_view(fig, azimuth=190)\n\nxy, im = mne.viz.snapshot_brain_montage(fig, raw.info)\nfig, ax = plt.subplots()\nax.axis('off')\nax.imshow(im)\nfor name, pos in xy.items():\n    if pos[0] >= 0 and pos[1] >= 0:  # no NaN locations\n        ax.text(*pos, name, ha='center', va='center', fontsize=4)\n\nevents, event_id = mne.events_from_annotations(raw)\nmne.viz.plot_events(events, raw.info['sfreq'], event_id=event_id, show=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create epochs around stimulation, visualize data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contact = 'LMS2'\ntmin, tmax = -1, 2\nbl_tmin, bl_tmax = -0.5, -0.05\n\n# try ``baseline=None`` for no baseline correction to play around\nmetadata = pd.read_csv(path.update(suffix='events'), sep='\\t')\nkeep = metadata.trial_type == 'electrical_stimulation'\nif 'status' in metadata:\n    keep = np.logical_and(keep, metadata.status == 'good')\nmetadata = metadata[keep]\nepochs = mne.Epochs(raw, events[keep],\n                    tmin=tmin, tmax=tmax,\n                    baseline=(bl_tmin, bl_tmax), picks=[contact],\n                    preload=True)\nepochs.metadata = metadata  # contains stimulation location information\n\n# unpack each pair separated by a hyphen, only use trials where\n# stimulation was delivered to channels other than the channel of\n# interest\nepochs.metadata['site1'], epochs.metadata['site2'] = np.array([\n    sites.split('-') for sites in\n    epochs.metadata.electrical_stimulation_site]).T\nexclude = np.in1d(epochs.metadata.site1, contact) | \\\n    np.in1d(epochs.metadata.site2, contact)\nepochs = epochs[~exclude]\n\nepochs.plot_image(picks=[contact], cmap='viridis', vmin=-250, vmax=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate BPCs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bpc_tmin, bpc_tmax = 0.015, 1\n\nstim_sites = epochs.metadata.electrical_stimulation_site\nV = epochs.get_data(tmin=bpc_tmin, tmax=bpc_tmax)[:, 0]  # select only channel\ntimes = epochs.times[(epochs.times >= bpc_tmin) & (epochs.times <= bpc_tmax)]\nV0 = V / np.linalg.norm(V, axis=1)[:, None]  # L2 norm each trial\nP = V0 @ V.T  # calculate internal projections\n\npairs = np.array(sorted(np.unique(stim_sites)))\ntmat = np.zeros((len(pairs), len(pairs)))\nfor i, pair1 in enumerate(pairs):\n    for j, pair2 in enumerate(pairs):\n        b = P[np.ix_(stim_sites == pair1, stim_sites == pair2)]\n        if i == j:  # subset without diagonal\n            b = np.concatenate([b[np.tril_indices(b.shape[0], k=-1)],\n                                b[np.triu_indices(b.shape[0], k=1)]])\n        b = b.ravel()\n        tmat[i, j] = np.mean(b) * np.sqrt(len(b)) / np.std(b, ddof=1)\n\nfig, ax = plt.subplots()\nimg = ax.imshow(tmat, vmin=0, vmax=10)\nax.set_xticks(range(tmat.shape[0]))\nax.set_xticklabels(pairs, rotation=90, fontsize=6)\nax.set_xlabel('Stimulation Pair')\nax.set_yticks(range(tmat.shape[0]))\nax.set_yticklabels(pairs, fontsize=6)\nax.set_ylabel('Stimulation Pair')\nax.set_title(r'Significance Matrix $\\Xi$', fontsize=15)\nfig.colorbar(img, ax=ax)\nfig.subplots_adjust(bottom=0.2)\nfig.show()\n\n\nt0 = tmat.copy()\nt0[t0 < 0] = 0\nt0[np.isnan(t0)] = 0\nt0 /= (np.max(t0))\n\ncluster_dim = 9\nn_reruns = 20\ntol = 1e-5\nrandom_state = 11\nfor n_components in range(cluster_dim, 1, -1):\n    this_error = None\n    for k in range(n_reruns):\n        model = NMF(n_components=n_components, init='random', solver='mu',\n                    tol=tol, max_iter=10000, random_state=random_state).fit(t0)\n        if this_error is None or model.reconstruction_err_ < this_error:\n            this_error = model.reconstruction_err_\n            W = model.transform(t0)\n            H = model.components_\n    H /= np.linalg.norm(H, axis=1)[:, None]\n    nmf_penalty = np.triu(H @ H.T, k=1).sum()\n    print(f'Inner dimension: {n_components}, off diagonal score: {nmf_penalty}')\n    if nmf_penalty < 1:\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "find stimulation trials for every BPC\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def kpca(X):\n    F, S, _ = np.linalg.svd(X.T)  # Compute the eigenvalues and right eigenvectors\n    ES = X @ F  # kernel trick\n    # divide through to obtain unit-normalized eigenvectors\n    E = ES / (np.ones((X.shape[0], 1)) @ S[None])\n    return E\n\n\n# find significant pairs per BPC; must be > threshold and greater than other BPCs\nbpc_pairs = np.zeros((len(pairs))) * np.nan  # index of bpc\nBs = np.zeros((n_components, V.shape[1]))  # n_BPCs x n_times\nfor bpc_idx in range(n_components):  # loop over BPCs\n    bpc_pair_idxs = np.where((H[bpc_idx] == np.max(H, axis=0)) &\n                             (H[bpc_idx] > 1 / (2 * np.sqrt(len(pairs)))))[0]\n    bpc_pairs[bpc_pair_idxs] = bpc_idx\n    bpc_trials = np.concatenate([np.where(stim_sites == pairs[idx])[0]\n                                 for idx in bpc_pair_idxs])\n    Bs[bpc_idx] = kpca(V[bpc_trials].T)[:, 0]  # basis vector is 1st PC\n    if np.mean(Bs[bpc_idx] @ V[bpc_trials].T) < 0:\n        Bs[bpc_idx] *= -1  # sign flip\n    print(bpc_idx, bpc_pair_idxs)\nexcluded_pairs = pairs[np.isnan(bpc_pairs)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot BPCs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colors = cm.tab10(np.linspace(0, 1, 10))\n\nfig, ax = plt.subplots(figsize=(5, 4))\nfor i, bpc in enumerate(Bs):\n    ax.plot(times, bpc, color=colors[i], label=i)\nax.set_xlabel('Time from stimulation (s)')\nax.set_ylabel('Normalized weight of BPCs')\nax.set_title('Calculated BPCs', fontsize=15)\nax.legend()\nfig.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "curve statistics\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alphas = np.zeros((len(stim_sites))) * np.nan\nepsilon2s = np.zeros((len(stim_sites))) * np.nan\nV2s = np.zeros((len(stim_sites))) * np.nan\nerrxprojs = np.zeros((len(pairs))) * np.nan\np_vals = np.zeros((len(pairs))) * np.nan\nplotweights = np.zeros((len(pairs))) * np.nan\nfor bpc_idx in range(n_components):  # loop over BPCs\n    # alpha coefficient weights for basis curve into V\n    bpc_alphas = Bs[bpc_idx] @ V.T\n    # residual epsilon (error timeseries) for basis bb after alpha*B coefficient fit\n    bpc_epsilon2 = V - (Bs[bpc_idx][:, None] @ bpc_alphas[None]).T\n    errxproj = bpc_epsilon2  @ bpc_epsilon2.T  # calculate all projections of error\n    V_selfproj = V @ V.T  # power in each trial\n\n    # cycle through pair types represented by this basis curve\n    for pair_idx in np.where(bpc_pairs == bpc_idx)[0]:\n        trials = stim_sites == pairs[pair_idx]\n        # alpha coefficient weights for basis curve bb into V\n        alphas[trials] = bpc_alphas[trials]\n        # self-submatrix of error projections\n        a = errxproj[np.ix_(trials, trials)]\n        epsilon2s[trials] = np.diag(a)\n        # sum-squared individual trials\n        V2s[trials] = np.diag(V_selfproj[np.ix_(trials, trials)])\n\n        # gather all off-diagonal elements from self-submatrix\n        b = np.concatenate([a[np.tril_indices(a.shape[0], k=-1)],\n                            a[np.triu_indices(a.shape[0], k=1)]])\n\n        # systematic residual structure within a stim pair group for a given basis will be\n        # given by set of native normalized internal cross-projections\n        errxproj[pair_idx] = np.mean(b) * np.sqrt(len(b)) / np.std(b, ddof=1)\n\n        plotweights[pair_idx] = np.mean(alphas[trials] / np.sqrt(epsilon2s[trials]))\n        T_stat, p_val = stats.ttest_1samp((alphas[trials] / np.sqrt(epsilon2s[trials])), 0)\n        p_vals[pair_idx] = p_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the final results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colors = cm.tab10(np.linspace(0, 1, 10))\n\nfig, ax = plt.subplots()\nax.axis('off')\nax.imshow(im)\nfor i, name in enumerate(pairs):\n    if np.isnan(bpc_pairs[i]):\n        continue\n    ch0, ch1 = name.split('-')\n    pos = (xy[ch0] + xy[ch1]) / 2\n    if pos[0] < 0 or pos[0] > im.shape[0] or pos[1] < 0 or pos[1] > im.shape[1]:\n        continue\n    color = colors[int(bpc_pairs[i])]\n    size = plotweights[i] * 200\n    ax.scatter(*pos, color=color[:3], s=[size], alpha=0.75)\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Put it all together into a function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "''' Work in progress\ndef bpcs(V, stim_sites, cluster_dim=10, n_reruns=20, tol=1e-5,\n         random_state=99, verbose=True):\n    \"\"\"Compute basis profile curves of an evoked response.\n\n    Parameters\n    ----------\n    V : np.ndarray (n_epochs, n_samples)\n        The voltage time course for the channel of interest.\n    stim_sites : np.ndarray (n_epochs)\n        The stimulation sites for each epoch.\n    cluster_dim : int\n        The maximum dimension of the clusters.\n    n_reruns : int\n        The number of reruns of non-negative matrix factorization\n        to ensure convergence.\n    tol : float\n        The convergence tolerance threshold.\n    random_state : int\n        Reproducibility seed.\n    verbose : bool\n        Whether to print function status updates.\n\n    Returns\n    -------\n    tmat : np.ndarray (n_pairs, n_pairs)\n        The projection matrix.\n    \"\"\"\n    V0 = V / np.linalg.norm(V, axis=1)[:, None]  # L2 norm each trial\n    P = V0 @ V.T  # calculate internal projections\n\n    pairs = np.array(sorted(np.unique(stim_sites)))\n    tmat = np.zeros((len(pairs), len(pairs)))\n    for i, pair1 in enumerate(pairs):\n        for j, pair2 in enumerate(pairs):\n            b = P[np.ix_(stim_sites == pair1, stim_sites == pair2)]\n            if i == j:  # subset without diagonal\n                b = np.concatenate([b[np.tril_indices(b.shape[0], k=-1)],\n                                    b[np.triu_indices(b.shape[0], k=1)]])\n            b = b.ravel()\n            tmat[i, j] = np.mean(b) * np.sqrt(len(b)) / np.std(b, ddof=1)\n\n    t0 = tmat.copy()\n    t0[t0 < 0] = 0\n    t0 /= (np.max(t0))\n\n    for n_components in range(cluster_dim, 1, -1):\n        this_error = None\n        for k in range(n_reruns):\n            model = NMF(n_components=n_components, init='random', solver='mu',\n                        tol=tol, max_iter=10000, random_state=random_state).fit(t0)\n            if this_error is None or model.reconstruction_err_ < this_error:\n                this_error = model.reconstruction_err_\n                W = model.transform(t0)\n                H = model.components_\n        H /= np.linalg.norm(H, axis=1)[:, None]\n        nmf_penalty = np.triu(H @ H.T, k=1).sum()\n        print(f'Inner dimension: {n_components}, off diagonal score: {nmf_penalty}')\n        if nmf_penalty < 1:\n            break\n\n    # find significant pairs per BPC; must be > threshold and greater than other BPCs\n    bpc_pairs = np.zeros((len(pairs))) * np.nan  # index of bpc\n    Bs = np.zeros((H.shape[0], V.shape[1]))  # n_BPCs x n_times\n    for bpc_idx in range(H.shape[0]):\n        bpc_pair_idxs = np.where((H[bpc_idx] == np.max(H, axis=0)) &\n                                 (H[bpc_idx] > 1 / (2 * np.sqrt(len(pairs)))))[0]\n        bpc_pairs[bpc_pair_idxs] = bpc_idx\n        bpc_trials = np.concatenate([np.where(stim_sites == pairs[idx])[0]\n                                     for idx in bpc_pair_idxs])\n        Bs[bpc_idx] = kpca(V[bpc_trials].T)[:, 0]  # basis vector is 1st PC\n        if np.mean(Bs[bpc_idx] @ V[bpc_trials].T) < 0:\n            Bs[bpc_idx] *= -1  # sign flip\n    excluded_pairs = pairs[np.isnan(bpc_pairs)]\n\n    # curve statistics\n    alphas = np.zeros((len()))\n    for bpc_idx, bpc_pairs in enumerate(pairs_per_bpc):  # cycle through basis curves\n        # alpha coefficient weights for basis curve into V\n        bpc_alphas = Bs[bpc_idx] @ V.T\n        # residual epsilon (error timeseries) for basis bb after alpha*B coefficient fit\n        ep = V - Bs[bpc_idx][None].T @ alphas[None]\n        errxproj = ep.T  @ ep  # calculate all projections of error\n        V_selfproj = V.T @ V  # power in each trial\n\n        # cycle through pair types represented by this basis curve\n        for pair_idx in range():\n            ind = (B_struct.pairs[bb])[n]\n            tmp_inds = pair_types['indices'][ind]  # indices for this pair type\n            # alpha coefficient weights for basis curve bb into V\n            (B_struct.alphas[bb]).append(al[tmp_inds])\n            # self-submatrix of error projections\n            a = errxproj[np.ix_(tmp_inds, tmp_inds)]\n            (B_struct.ep2[bb]).append((np.diag(a)).T)  # sum-squared error\n            # sum-squared individual trials\n            (B_struct.V2[bb]).append(\n                np.diag(V_selfproj[np.ix_(tmp_inds, tmp_inds)]).T)\n\n            # gather all off-diagonal elements from self-submatrix\n            b = []\n            # for q=1:(size(a,2)-1), b=[b a(q,(q+1):end)]; end\n            for q in range(a.shape[1]-1):\n                b.extend(a[q, q+1:])\n            # for q=2:(size(a,2)), b=[b a(q,1:(q-1))]; end\n            for q in range(1, a.shape[1]):\n                b.extend(a[q, :q-1])\n\n            # systematic residual structure within a stim pair group for a given basis will be\n            # given by set of native normalized internal cross-projections\n            B_struct.errxproj[bb] = b\n\n    # projection weights\n    p_vals = np.zeros(())\n    plotweights = np.zeros(())\n    for q in range(Bs.shape[0]):  # cycle through basis curves\n        # cycle through pair types represented by this basis curve\n        for n in range(B_struct.pairs[q].shape[0]):\n            curr_alphas = B_struct.alphas[q][n]\n            curr_ep2_5 = (B_struct.ep2[q][n])**0.5\n            # alphas normalized by error magnitude\n            plotweights[q].append(np.mean(curr_alphas / curr_ep2_5))\n\n            # significance alphas normalized by error magnitude\n            t, pVal = stats.ttest_1samp((curr_alphas / curr_ep2_5), 0)\n            (B_struct.p[q]).append(pVal)\n\n    return tmat, Bs, excluded_pairs\n'''"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}